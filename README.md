# JapanInside

## Table des matiÃ¨res
- [Badges](#badges)
- [Ã‰quipe](#Ã©quipe)
- [Descriptif](#descriptif)
- [IdÃ©e](#idÃ©e)
- [Stack technique](#stack-technique)
- [Structure du projet](#structure-du-projet)
- [Setup](#setup)
- [Pipeline CI](#pipeline-ci)
- [Makefiles](#makefiles)
- [Pipeline CD](#pipeline-cd)
- [DÃ©ploiement avec Minikube](#dÃ©ploiement-avec-minikube)

---

## Badges

[![CI Frontend](https://github.com/Les-Kimono/JapanInside/actions/workflows/ci-frontend.yml/badge.svg)](https://github.com/ORG/Les-Kimono/JapanInside/workflows/ci-frontend.yml)  
[![CI Backend](https://github.com/Les-Kimono/JapanInside/actions/workflows/ci-backend.yml/badge.svg)](https://github.com/ORG/Les-Kimono/JapanInside/workflows/ci-backend.yml)

![Status](https://img.shields.io/badge/status-en%20dÃ©veloppement-orange?style=for-the-badge)  
![Licence](https://img.shields.io/github/license/Les-Kimono/JapanInside?style=for-the-badge)  
![Dernier commit](https://img.shields.io/github/last-commit/Les-Kimono/JapanInside?style=for-the-badge)  
![Contributeurs](https://img.shields.io/github/contributors/Les-Kimono/JapanInside?style=for-the-badge)  
![Ã‰quipe](https://img.shields.io/badge/team-Les--Kimono-blue?style=for-the-badge)  

---

## Ã‰quipe

- [@justine](https://github.com/WitheredFlower10)  
- [@lucas](https://github.com/luucas7)  
- [@adrien](https://github.com/baffionia)  
- [@jordan](https://github.com/ZedRoff)  
- [@auguste](https://github.com/ZedRoff)  
- [@aman](https://github.com/ZedRoff)  

---

## Descriptif

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre de l'unitÃ© DevOps, encadrÃ©e par M. Badr TAJINI, en 2Ã¨me annÃ©e d'ingÃ©nieur Ã  l'Ã©cole ESIEE Paris (E4FI).

Lâ€™objectif est dâ€™appliquer les pratiques DevOps sur un projet existant : pipelines CI/CD, dockerisation, Kubernetes (Minikube) et gestion du travail collaboratif sur GitHub.

---

## IdÃ©e

JapanInside est une application full-stack pour organiser un voyage au Japon.  

- **Front-office** : visualisation des Ã©tapes du voyage, attractions et spÃ©cialitÃ©s culinaires.  
- **Back-office** : gestion et Ã©dition du voyage, ajout dâ€™Ã©tapes, attractions et recettes.

---

## Stack technique

| CÃ´tÃ© | Technologie |
|------|------------|
| Front-End | ReactJS |
| Back-End | FastAPI |
| Base de donnÃ©es | PostgreSQL |
| Conteneurisation | Docker |
| Orchestration | Kubernetes (Minikube) |
| Load Balancing | Service LoadBalancer (3 replicas) |
| Registry | Docker Hub |

---

## Structure du projet

```
.
â”œâ”€â”€ backend
â”‚   â”œâ”€â”€ crud
â”‚   â”œâ”€â”€ data
â”‚   â”œâ”€â”€ models
â”‚   â”œâ”€â”€ routes
â”‚   â”œâ”€â”€ schemas
â”‚   â”œâ”€â”€ tests
â”‚   â””â”€â”€ utils
â”œâ”€â”€ frontend
â”‚   â”œâ”€â”€ public
â”‚   â””â”€â”€ src
â”œâ”€â”€ k8s
â”‚   â”œâ”€â”€ backend
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â”œâ”€â”€ config
â”‚   â”‚   â””â”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ db
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â””â”€â”€ frontend
â”‚       â”œâ”€â”€ deployment.yaml
â”‚       â””â”€â”€ service.yaml
â””â”€â”€ scripts
    â”œâ”€â”€ bash/              # Scripts bash (Linux/Mac)
    â”‚   â”œâ”€â”€ deploy.sh
    â”‚   â”œâ”€â”€ tunnel.sh
    â”‚   â”œâ”€â”€ status.sh
    â”‚   â”œâ”€â”€ logs.sh
    â”‚   â””â”€â”€ clean.sh
    â”œâ”€â”€ deploy.ps1         # Scripts PowerShell (Windows)
    â”œâ”€â”€ tunnel.ps1
    â”œâ”€â”€ status.ps1
    â”œâ”€â”€ logs.ps1
    â””â”€â”€ clean.ps1
```

Le projet inclut des **tests unitaires** pour le front et le back, des **Makefiles**, des **pre-commit hooks**, des **scripts de dÃ©ploiement PowerShell**, et un code prÃªt pour la production avec **load balancing**.

---

## Setup

### Installation

Cloner le projet :  

**HTTPS :**
```bash
git clone https://github.com/Les-Kimono/JapanInside.git japan-inside
```

**SSH :**
```bash
git clone git@github.com:Les-Kimono/JapanInside.git japan-inside
```

Puis accÃ©der au dossier :
```bash
cd japan-inside
```

---

### Lancement du projet

```bash
make first-install
make start
make stop
make start
```

> Les deux derniÃ¨res Ã©tapes sont nÃ©cessaires pour que la base de donnÃ©es se crÃ©e correctement.

---

### DÃ©veloppement local

```bash
git checkout staging
make restart
```

---
## Images Docker

```
https://hub.docker.com/r/luucas71/japaninside-frontend
https://hub.docker.com/r/luucas71/japaninside-backend
```
## Pipeline CI

Deux pipelines distincts sont utilisÃ©s pour le front-end et le back-end.

### Front-end

- Setup
- Linting
- Security Check
- Build
- Unit Testing

### Back-end

- Setup
- Code Sniffing
- Linting
- Safety Check
- Unit Testing

---

## Makefiles

Trois Makefiles sont prÃ©sents :

1. **Racine** : lancer Kubernetes, tests unitaires front et back, build Docker.  
2. **Backend** : tests unitaires, linting, code sniffing, container back.  
3. **Frontend** : tests unitaires, linting, code sniffing, container front.  

---

## Pipeline CD

Le pipeline de dÃ©ploiement continu (CD) automatise le processus de mise en production de l'application sur Kubernetes.

### Workflow de dÃ©ploiement

Lors d'un push sur la branche `main`, le pipeline s'exÃ©cute automatiquement :

#### 1. Build des images Docker

Deux images de production sont construites Ã  partir des Dockerfiles optimisÃ©s :

- **Backend** : `Dockerfile.prod` avec FastAPI + Uvicorn
- **Frontend** : `Dockerfile.prod` avec build optimisÃ© Vite

Les images sont taguÃ©es avec :
- `latest` pour la version la plus rÃ©cente
- Le hash du commit Git pour traÃ§abilitÃ©

#### 2. Push sur Docker Hub

Les images sont poussÃ©es sur Docker Hub dans le repository public :

```
luucas71/japaninside-backend:latest
luucas71/japaninside-frontend:latest
```

#### 3. DÃ©ploiement sur Kubernetes (Minikube)

Les images sont automatiquement dÃ©ployÃ©es sur un cluster Kubernetes local (Minikube) qui simule un environnement de production.

**Architecture dÃ©ployÃ©e :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LoadBalancer Service          â”‚
â”‚   (Distribution automatique)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       â”‚        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”
â”‚Pod 1 â”‚ â”‚Pod 2â”‚ â”‚Pod 3â”‚
â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
```

**Composants dÃ©ployÃ©s :**

- **PostgreSQL** : Base de donnÃ©es avec PersistentVolumeClaim
- **Backend** : 3 replicas avec LoadBalancer
- **Frontend** : 3 replicas avec LoadBalancer

**Avantages du load balancing :**

- RÃ©partition automatique du trafic entre les pods (round-robin)
- Haute disponibilitÃ© : si un pod tombe, le trafic est redirigÃ© vers les autres
- ScalabilitÃ© : possibilitÃ© d'ajuster le nombre de replicas selon la charge
- Auto-healing : redÃ©marrage automatique des pods dÃ©faillants

---

## DÃ©ploiement avec Minikube

### Linux / Mac

#### PrÃ©requis

- **Minikube**
- **kubectl**
- **make**

#### DÃ©marrage rapide avec Makefile

Le Makefile simplifie toutes les commandes.

**Terminal 1 : DÃ©ploiement**
```bash
make deploy
```

Ce qui va se passer :
- VÃ©rification et dÃ©marrage de Minikube si nÃ©cessaire
- DÃ©ploiement du namespace `japaninside`
- DÃ©ploiement de PostgreSQL (attente qu'il soit prÃªt)
- DÃ©ploiement du backend (3 replicas)
- DÃ©ploiement du frontend (3 replicas)
- Attente que tous les pods soient prÃªts

**Terminal 2 : Tunnel LoadBalancer** (dans un nouveau terminal)
```bash
make tunnel
```

- Ce terminal doit rester ouvert pendant toute la session !
- Vous aurez besoin de `sudo`

**VÃ©rifier le statut** (retour au Terminal 1)
```bash
make status
```

Affiche les pods, services, et URLs d'accÃ¨s !

#### Commandes disponibles

| Commande | Description |
|----------|-------------|
| `make deploy` | DÃ©ploie l'application complÃ¨te avec LoadBalancer |
| `make tunnel` | Lance le tunnel Minikube (requis, garder ouvert) |
| `make status` | Affiche l'Ã©tat des pods et les URLs d'accÃ¨s |
| `make logs-backend` | Logs en temps rÃ©el du backend |
| `make logs-frontend` | Logs en temps rÃ©el du frontend |
| `make logs-all` | Logs de tous les services |
| `make endpoints` | Affiche les endpoints (distribution du trafic) |
| `make scale-up` | Scale Ã  5 replicas (backend + frontend) |
| `make scale-down` | Scale Ã  2 replicas |
| `make clean` | Supprime tous les dÃ©ploiements |
| `make redeploy` | Nettoie et redÃ©ploie |
| `make help` | Affiche toutes les commandes disponibles |

#### Workflow complet

```bash
# Terminal 1
make deploy
make status

# Terminal 2 (nouveau terminal, laisser ouvert)
make tunnel

# Terminal 1 (aprÃ¨s quelques secondes)
make status  # Voir les URLs avec IPs externes

# Ouvrir dans le navigateur l'URL affichÃ©e !

# Voir les logs en temps rÃ©el
make logs-backend

# Scaler selon les besoins
make scale-up      # Plus de capacitÃ©
make scale-down    # Ã‰conomiser les ressources

# Nettoyage
make clean
```

---

### ğŸªŸ Windows

#### PrÃ©requis

- **Minikube**
- **kubectl** 
- **PowerShell**

#### DÃ©marrage rapide avec PowerShell

**Terminal 1 : DÃ©ploiement** (PowerShell en Administrateur)

```powershell
.\scripts\deploy.ps1
```

Ce qui va se passer :
- VÃ©rification et dÃ©marrage de Minikube si nÃ©cessaire
- DÃ©ploiement du namespace `japaninside`
- DÃ©ploiement de PostgreSQL (attente qu'il soit prÃªt)
- DÃ©ploiement du backend (3 replicas)
- DÃ©ploiement du frontend (3 replicas)
- Attente que tous les pods soient prÃªts

**Terminal 2 : Tunnel LoadBalancer** (nouveau PowerShell en Administrateur)

```powershell
.\scripts\tunnel.ps1
```

- Ce terminal doit rester ouvert pendant toute la session !
- NÃ©cessite les privilÃ¨ges Administrateur

**VÃ©rifier le statut** (retour au Terminal 1)

```powershell
.\scripts\status.ps1
```

Affiche les pods, services, et URLs d'accÃ¨s.

#### Scripts disponibles

| Script | Description |
|--------|-------------|
| `.\scripts\deploy.ps1` | DÃ©ploie l'application complÃ¨te |
| `.\scripts\tunnel.ps1` | Lance le tunnel (requis, garder ouvert) |
| `.\scripts\status.ps1` | Affiche l'Ã©tat et les URLs |
| `.\scripts\logs.ps1` | Logs backend (par dÃ©faut) |
| `.\scripts\logs.ps1 frontend` | Logs frontend |
| `.\scripts\logs.ps1 all` | Logs de tous les services |
| `.\scripts\clean.ps1` | Supprime tous les dÃ©ploiements |

#### Scaling manuel (Windows)

```powershell
# Augmenter Ã  5 replicas
kubectl scale deployment backend -n japaninside --replicas=5
kubectl scale deployment frontend -n japaninside --replicas=5

# RÃ©duire Ã  2 replicas
kubectl scale deployment backend -n japaninside --replicas=2
kubectl scale deployment frontend -n japaninside --replicas=2

# VÃ©rifier
kubectl get pods -n japaninside
```

#### Workflow complet

```powershell
# Terminal 1 (PowerShell Administrateur)
.\scripts\deploy.ps1
.\scripts\status.ps1

# Terminal 2 (nouveau PowerShell Administrateur, laisser ouvert)
.\scripts\tunnel.ps1

# Terminal 1 (aprÃ¨s quelques secondes)
.\scripts\status.ps1  # Voir les URLs avec IPs externes

# Ouvrir dans le navigateur l'URL affichÃ©e !

# Voir les logs
.\scripts\logs.ps1

# Nettoyage
.\scripts\clean.ps1
```


Ouvrir PowerShell avec "ExÃ©cuter en tant qu'administrateur"

---

### Configuration LoadBalancer

Les services utilisent le type `LoadBalancer` pour distribuer automatiquement le trafic entre les replicas.

**Fichier : `k8s/backend/service.yaml`**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: backend
  namespace: japaninside
spec:
  type: LoadBalancer
  selector:
    app: backend
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
```